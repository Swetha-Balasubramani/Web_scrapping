# Web_scrapping
This project demonstrates an end-to-end data engineering and analysis pipeline built using Python. It covers web scraping, data cleaning, exploratory data analysis (EDA), and database storage, showcasing practical experience with real-world data workflows.

üìÇ Project Workflow
1Ô∏è‚É£ Data Collection (datacollection.ipynb)

Extracted real-world data from web sources using Python web scraping techniques

Parsed HTML content to collect structured information

Ensured scalable and reusable scraping logic

Skills demonstrated:
Web Scraping, Requests, BeautifulSoup, Data Extraction

2Ô∏è‚É£ Data Cleaning & Preprocessing (datacleaning.ipynb)

Cleaned raw scraped data for accuracy and consistency

Handled missing values, duplicates, and incorrect data types

Prepared data for analysis and storage

Skills demonstrated:
Pandas, Data Cleaning, Preprocessing, Data Quality Handling

3Ô∏è‚É£ Exploratory Data Analysis (eda.ipynb)

Performed EDA to identify trends, patterns, and insights

Used visualizations and statistical summaries

Converted raw data into meaningful insights

Skills demonstrated:
EDA, Data Visualization, Analytical Thinking

4Ô∏è‚É£ Database Storage (store_db.ipynb)

Designed and stored structured data in an SQLite database

Created tables and inserted cleaned data

Enabled efficient data retrieval for future analysis

Skills demonstrated:
SQLite, Database Design, Data Persistence

üóÑÔ∏è Database

vaaree_data.db: SQLite database containing the processed and structured dataset
